import pdb
from utils import obtain_dataset, get_dataset_list
from utils import form_dataset, batched_data_with_indices, clean_dataset, results_caculate_and_draw
from transformers import GPTNeoXForCausalLM, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import argparse
from tqdm import tqdm
import torch.quantization
import os
import pickle
import numpy as np
import evaluate
import pandas as pd
from bleurt_pytorch import BleurtConfig, BleurtForSequenceClassification, BleurtTokenizer


def get_ed(a, b):
    if len(b) == 0:
        return len(a)
    elif len(a) == 0:
        return len(b)
    else:
        dist = np.zeros((len(a) + 1, len(b) + 1))
        for i in range(len(a)):
            for j in range(len(b)):
                if a[i] == b[j]:
                    dist[i + 1, j + 1] = dist[i, j]
                else:
                    dist[i + 1, j + 1] = 1 + min(dist[i, j], dist[i + 1, j], dist[i, j + 1])

        return int(dist[-1, -1])


def get_peak(samples, s_0, alpha):
    lengths = [len(x) for x in samples]
    l = min(lengths)
    l = min(l, 100)
    thresh = int(np.ceil(alpha * l))
    distances = [get_ed(s, s_0) for s in samples]
    rhos = [len([x for x in distances if x == d]) for d in range(0, thresh + 1)]
    peak = sum(rhos)

    return peak
# def bleurt_score(bleurt, predictions, references):
#     """Compute the average BLEURT score over the gpt responses
#
#     Args:
#         predictions (list): List of gpt responses generated by GPT-3.5 under a certain instruction
#         references (list): List of sentence 2 collected from raw dataset (e.g. wnli)
#
#     Returns:
#         bluert_scores: List of bluert scores
#     """
#     bluert_scores = bleurt.compute(predictions=predictions,
#                                    references=references)['scores']
#     return bluert_scores


def rougeL_score(predictions, references):
    """Compute the rougel score over the gpt responses

    Args:
        predictions (list): List of gpt responses generated by GPT-3.5 under a certain instruction
        references (list): List of sentence 2 collected from raw dataset (e.g. wnli)

    Returns:
        rougeL_scores: List of rougeL scores
    """
    rougeL_score = rouge.compute(predictions=predictions,
                                 references=references, use_aggregator=False)['rougeL']
    return rougeL_score

def bleurt_score(bleurt, tokenizer, reference, generations, args):
    bleurt.eval()
    with torch.no_grad():
        inputs = tokenizer([reference for i in range(len(generations))], generations, padding='longest', return_tensors='pt')
        inputs = {key: value.to(args.refer_cuda) for key, value in inputs.items()}
        res = bleurt(**inputs).logits.flatten().tolist()
    return res

def compute_black_box_mia(args):
    dataset_names = get_dataset_list(args)
    # bnb_config = BitsAndBytesConfig(
    #         load_in_8bit=True,  # 开启8位量化
    #         bnb_8bit_use_double_quant=True,  # 使用双重量化技术
    #         bnb_8bit_compute_dtype=torch.float16  # 计算过程中使用float16
    #     )
    model = GPTNeoXForCausalLM.from_pretrained(
        f"EleutherAI/pythia-{args.model_size}-deduped",
        revision="step143000",
        cache_dir=f"./pythia-{args.model_size}-deduped/step143000",
        torch_dtype=torch.bfloat16,
        #quantization_config=bnb_config
    ).cuda(args.cuda).eval()
    tokenizer = AutoTokenizer.from_pretrained(
      f"EleutherAI/pythia-{args.model_size}-deduped",
      revision="step143000",
      cache_dir=f"./pythia-{args.model_size}-deduped/step143000",
    )
    tokenizer.pad_token = tokenizer.eos_token
    model.generation_config.pad_token_id = model.generation_config.eos_token_id
    model.generation_config.return_dict_in_generate = True
    #bleurt = evaluate.load('bleurt', 'bleurt-20', model_type="metric")
    bleurt_model = BleurtForSequenceClassification.from_pretrained('lucadiliello/BLEURT-20').cuda(args.refer_cuda)
    bleurt_tokenizer = BleurtTokenizer.from_pretrained('lucadiliello/BLEURT-20')
    bleurt_model.eval()
    for dataset_name in dataset_names:
        df = pd.DataFrame()
        if args.same_length == "True":
            if os.path.isfile(f"{args.save_dir}/{dataset_name}/{args.relative}/{args.truncated}/{args.min_len}_{args.model_size}_same_length.csv"):
                df = pd.read_csv(f"{args.save_dir}/{dataset_name}/{args.relative}/{args.truncated}/{args.min_len}_{args.model_size}_same_length.csv")
        else:
            if os.path.isfile(f"{args.save_dir}/{dataset_name}/{args.relative}/{args.truncated}/{args.min_len}_{args.model_size}_all_length.csv"):
                df = pd.read_csv(f"{args.save_dir}/{dataset_name}/{args.relative}/{args.truncated}/{args.min_len}_{args.model_size}_all_length.csv")
        dataset = obtain_dataset(dataset_name, args)
        device = f'cuda:{args.cuda}'
        generation_samples_list = []
        ccd_dict = {}
        samia_dict = {}
        ccd_dict[dataset_name] = {"member": [], "nonmember": []}
        samia_dict[dataset_name] = {"member": [], "nonmember": []}
        for set_name in ["member", "nonmember"]:
            cleaned_data, orig_indices = clean_dataset(dataset[set_name])
            for idx, (data_batch, orig_indices_batch) in tqdm(enumerate(batched_data_with_indices(cleaned_data, orig_indices, batch_size=args.generation_batch_size))):
                orig_idx = [item for item in orig_indices_batch]
                batched_text = [item for item in data_batch]
                tokenized_inputs = tokenizer(batched_text, return_tensors="pt", truncation=True, padding=True,
                                             max_length=1024)
                tokenized_inputs = {key: val.to(device) for key, val in tokenized_inputs.items()}
                full_decoded = []
                input_length = int(tokenized_inputs["attention_mask"][0].sum()/2) if (tokenized_inputs["attention_mask"][0].sum()
                                                                               < args.max_input_tokens) else args.max_input_tokens
                for _ in tqdm(range(args.generation_samples)):
                    if _ == 0:
                        zero_temp_generation = model.generate(tokenized_inputs["input_ids"][0][:input_length].unsqueeze(0),
                                                     temperature=0,
                                                     max_new_tokens=args.max_new_tokens,
                                                    )
                        full_decoded.append(tokenizer.decode(zero_temp_generation["sequences"][0][input_length:], skip_special_tokens=True))
                    else:
                        generations = model.generate(tokenized_inputs["input_ids"][0][:input_length].unsqueeze(0),
                                                 do_sample=True,
                                                 temperature=args.temperature,
                                                 max_new_tokens=args.max_new_tokens,
                                                 top_k=50,
                                                )
                        full_decoded.append(tokenizer.decode(generations["sequences"][0][input_length:], skip_special_tokens=True))
                pdb.set_trace()
                peak = get_peak(full_decoded[1:], full_decoded[0], 0.05)
                bleurt_value = np.array(bleurt_score(bleurt_model, bleurt_tokenizer,  full_decoded[0], full_decoded[1:], args)).mean().item()
                ccd_dict[dataset_name][set_name].extend(peak)
                samia_dict[dataset_name][set_name].extend(bleurt_value)
        os.makedirs(args.save_dir, exist_ok=True)
        os.makedirs(f"{args.save_dir}/{dataset_name}/{args.relative}/{args.truncated}", exist_ok=True)
        pickle.dump(ccd_dict, open(f"{args.save_dir}/{dataset_name}/{args.relative}/{args.truncated}/{args.min_len}_{args.model_size}_ccd_dict.pkl", "wb"))
        pickle.dump(samia_dict, open(f"{args.save_dir}/{dataset_name}/{args.relative}/{args.truncated}/{args.min_len}_{args.model_size}_samia_dict.pkl", "wb"))
        df = results_caculate_and_draw(dataset_name, args, df, method_list=["ccd", "samia"])
        if args.same_length:
            df.to_csv(f"{args.save_dir}/{dataset_name}/{args.relative}/{args.truncated}/{args.min_len}_{args.model_size}_same_length.csv")
        else:
            df.to_csv(f"{args.save_dir}/{dataset_name}/{args.relative}/{args.truncated}/{args.min_len}_{args.model_size}_all_length.csv")
