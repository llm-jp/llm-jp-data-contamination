import evaluate
import argparse
import pickle
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
import pandas as pd
def bleurt_score(predictions, references):
    """Compute the average BLEURT score over the gpt responses

    Args:
        predictions (list): List of gpt responses generated by GPT-3.5 under a certain instruction
        references (list): List of sentence 2 collected from raw dataset (e.g. wnli)

    Returns:
        bluert_scores: List of bluert scores
    """
    bluert_scores = bleurt.compute(predictions=predictions,
                                   references=references)['scores']
    return bluert_scores


def rougeL_score(predictions, references):
    """Compute the rougel score over the gpt responses

    Args:
        predictions (list): List of gpt responses generated by GPT-3.5 under a certain instruction
        references (list): List of sentence 2 collected from raw dataset (e.g. wnli)

    Returns:
        rougeL_scores: List of rougeL scores
    """
    rougeL_score = rouge.compute(predictions=predictions,
                                 references=references, use_aggregator=False)['rougeL']
    return rougeL_score

parser = argparse.ArgumentParser()
parser.add_argument("--batch_size", type=int, default=1)
parser.add_argument("--model_size", type=str, default="410m")
parser.add_argument("--dataset_name", type=str, default="all", choices=["arxiv", "dm_mathematics", "github", "hackernews", "pile_cc",
                     "pubmed_central", "wikipedia_(en)", "full_pile","WikiMIA64", "WikiMIA128","WikiMIA256",
                      "WikiMIAall"])
parser.add_argument("--cuda", type=int, default=1, help="cuda device")
parser.add_argument("--skip_calculation", type=str, default="True")
parser.add_argument("--reference_model", type=str, default="True")
parser.add_argument("--samples", type=int, default=1000)
parser.add_argument("--generation_samples", type=int, default=10)
args = parser.parse_args()



bleurt =  evaluate.load('bleurt', 'bleurt-20',
                        model_type="metric")
rouge = evaluate.load('rouge')
if args.dataset_name == "all":
    dataset_names = ["arxiv", "dm_mathematics", "github", "hackernews", "pile_cc",
                    "pubmed_central", "wikipedia_(en)", "full_pile","WikiMIA64", "WikiMIA128","WikiMIA256",
                     "WikiMIAall"]
    #dataset_names = ["WikiMIAall"]
else:
    dataset_names = [args.dataset_name]
results = pd.DataFrame(columns=["Dataset", "member_bleurt", "member_rouge", "nonmember_bleurt", "nonmember_rouge"])
for dataset_name in dataset_names:
    temp_input_length = 48
    f = open(f"sem_mem_score_online/{args.model_size}/{dataset_name}_{temp_input_length}_generation_samples.pkl", "rb")
    data = pickle.load(f)
    f.close()
    half = len(data)//2
    member_bleurt = []
    member_rouge = []
    nonmember_bleurt = []
    nonmember_rouge = []
    for idx, example in tqdm(enumerate(data)):
        original_text = example[0]
        full_generated_texts = example[1]
        partial_generated_texts = example[2]
        references = example[3]
        bleurt_value = np.array(bleurt_score(partial_generated_texts, [references for _ in range(args.generation_samples)])).mean()
        rougle_value = np.array(rougeL_score(partial_generated_texts, [references for _ in range(args.generation_samples)])).mean()
        if idx < half:
            member_bleurt.append(bleurt_value)
            member_rouge.append(rougle_value)
        else:
            nonmember_bleurt.append(bleurt_value)
            nonmember_rouge.append(rougle_value)
    results._append(pd.DataFrame({"Dataset": [dataset_name for _ in range(member_bleurt)], "member_bleurt": member_bleurt, "member_rouge": member_rouge,
                                  "nonmember_bleurt": nonmember_bleurt, "nonmember_rouge": nonmember_rouge}))
    plt.hist(member_bleurt, bins=50, alpha=0.5, label="member_bleurt")
    plt.hist(nonmember_bleurt, bins=50, alpha=0.5, label="nonmember_bleurt")
    plt.hist(member_rouge, bins=50, alpha=0.5, label="member_rouge")
    plt.hist(nonmember_rouge, bins=50, alpha=0.5, label="nonmember_rouge")
    plt.legend()
    plt.savefig(f"sem_mem_score_online/{args.model_size}/{dataset_name}.png")
    plt.show()
    # Save to a csv file
results.to_csv(f'sem_mem_score_online/{args.model_size}/sem_score_results.csv', index=False)


